{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install contextily\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0g_HbhCGQXF",
        "outputId": "67207dc2-b772-441d-f86f-139b137e950d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contextily\n",
            "  Downloading contextily-1.6.2-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (from contextily) (2.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from contextily) (3.10.0)\n",
            "Collecting mercantile (from contextily)\n",
            "  Downloading mercantile-1.2.1-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from contextily) (11.2.1)\n",
            "Collecting rasterio (from contextily)\n",
            "  Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from contextily) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from contextily) (1.4.2)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from contextily) (2025.4.0)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy->contextily) (2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->contextily) (2.9.0.post0)\n",
            "Requirement already satisfied: click>=3.0 in /usr/local/lib/python3.11/dist-packages (from mercantile->contextily) (8.1.8)\n",
            "Collecting affine (from rasterio->contextily)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (25.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from rasterio->contextily) (2025.4.26)\n",
            "Collecting cligj>=0.5 (from rasterio->contextily)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio->contextily)\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->contextily) (2.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->contextily) (1.17.0)\n",
            "Downloading contextily-1.6.2-py3-none-any.whl (17 kB)\n",
            "Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading rasterio-1.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Installing collected packages: mercantile, cligj, click-plugins, affine, rasterio, contextily\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 contextily-1.6.2 mercantile-1.2.1 rasterio-1.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CmMWYkCFWPR",
        "outputId": "cf19b175-6ab5-4adf-ea66-750119f6e197"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysal\n",
            "  Downloading pysal-25.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.10 in /usr/local/lib/python3.11/dist-packages (from pysal) (4.13.4)\n",
            "Requirement already satisfied: geopandas>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pysal) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.0.2)\n",
            "Requirement already satisfied: packaging>=22 in /usr/local/lib/python3.11/dist-packages (from pysal) (24.2)\n",
            "Requirement already satisfied: pandas>=1.4 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.2.2)\n",
            "Requirement already satisfied: platformdirs>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from pysal) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.27 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.8 in /usr/local/lib/python3.11/dist-packages (from pysal) (1.15.2)\n",
            "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from pysal) (2.1.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1 in /usr/local/lib/python3.11/dist-packages (from pysal) (1.6.1)\n",
            "Collecting libpysal>=4.12.1 (from pysal)\n",
            "  Downloading libpysal-4.13.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting access>=1.1.9 (from pysal)\n",
            "  Downloading access-1.1.9-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting esda>=2.6.0 (from pysal)\n",
            "  Downloading esda-2.7.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting giddy>=2.3.6 (from pysal)\n",
            "  Downloading giddy-2.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inequality>=1.1.1 (from pysal)\n",
            "  Downloading inequality-1.1.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting pointpats>=2.5.1 (from pysal)\n",
            "  Downloading pointpats-2.5.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting segregation>=2.5.1 (from pysal)\n",
            "  Downloading segregation-2.5.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting spaghetti>=1.7.6 (from pysal)\n",
            "  Downloading spaghetti-1.7.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mgwr>=2.2.1 (from pysal)\n",
            "  Downloading mgwr-2.2.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting momepy>=0.9.1 (from pysal)\n",
            "  Downloading momepy-0.10.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting spglm>=1.1.0 (from pysal)\n",
            "  Downloading spglm-1.1.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting spint>=1.0.7 (from pysal)\n",
            "  Downloading spint-1.0.7.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting spreg>=1.8.1 (from pysal)\n",
            "  Downloading spreg-1.8.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tobler>=0.12.1 (from pysal)\n",
            "  Downloading tobler-0.12.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting mapclassify>=2.8.1 (from pysal)\n",
            "  Downloading mapclassify-2.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting splot>=1.1.7 (from pysal)\n",
            "  Downloading splot-1.1.7-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting spopt>=0.6.1 (from pysal)\n",
            "  Downloading spopt-0.6.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.10->pysal) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.10->pysal) (4.13.2)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.11/dist-packages (from geopandas>=0.10.0->pysal) (0.10.0)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from geopandas>=0.10.0->pysal) (3.7.1)\n",
            "Collecting quantecon>=0.7 (from giddy>=2.3.6->pysal)\n",
            "  Downloading quantecon-0.8.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from inequality>=1.1.1->pysal) (3.10.0)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.11/dist-packages (from mapclassify>=2.8.1->pysal) (3.4.2)\n",
            "Requirement already satisfied: tqdm>=4.65 in /usr/local/lib/python3.11/dist-packages (from momepy>=0.9.1->pysal) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->pysal) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->pysal) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.4->pysal) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->pysal) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->pysal) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->pysal) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27->pysal) (2025.4.26)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->pysal) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1->pysal) (3.6.0)\n",
            "Collecting deprecation (from segregation>=2.5.1->pysal)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal) (0.13.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from segregation>=2.5.1->pysal) (0.60.0)\n",
            "Collecting rtree>=1.0 (from spaghetti>=1.7.6->pysal)\n",
            "  Downloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting pulp>=2.7 (from spopt>=0.6.1->pysal)\n",
            "  Downloading pulp-3.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.11/dist-packages (from tobler>=0.12.1->pysal) (1.4.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (from tobler>=0.12.1->pysal) (0.14.4)\n",
            "Collecting rasterstats (from tobler>=0.12.1->pysal)\n",
            "  Downloading rasterstats-0.20.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->inequality>=1.1.1->pysal) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.4->pysal) (1.17.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from quantecon>=0.7->giddy>=2.3.6->pysal) (1.13.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->segregation>=2.5.1->pysal) (0.43.0)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.11/dist-packages (from rasterio->tobler>=0.12.1->pysal) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.11/dist-packages (from rasterio->tobler>=0.12.1->pysal) (25.3.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.11/dist-packages (from rasterio->tobler>=0.12.1->pysal) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.11/dist-packages (from rasterio->tobler>=0.12.1->pysal) (0.7.2)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.11/dist-packages (from rasterio->tobler>=0.12.1->pysal) (1.1.1)\n",
            "Collecting fiona (from rasterstats->tobler>=0.12.1->pysal)\n",
            "  Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from rasterstats->tobler>=0.12.1->pysal) (3.20.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels->tobler>=0.12.1->pysal) (1.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->quantecon>=0.7->giddy>=2.3.6->pysal) (1.3.0)\n",
            "Downloading pysal-25.1-py3-none-any.whl (17 kB)\n",
            "Downloading access-1.1.9-py3-none-any.whl (21 kB)\n",
            "Downloading esda-2.7.0-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.8/142.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading giddy-2.3.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inequality-1.1.1-py3-none-any.whl (29 kB)\n",
            "Downloading libpysal-4.13.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mapclassify-2.8.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mgwr-2.2.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading momepy-0.10.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pointpats-2.5.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading segregation-2.5.2-py3-none-any.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.6/141.6 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spaghetti-1.7.6-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spglm-1.1.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading splot-1.1.7-py3-none-any.whl (39 kB)\n",
            "Downloading spopt-0.6.1-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.1/243.1 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spreg-1.8.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tobler-0.12.1-py3-none-any.whl (28 kB)\n",
            "Downloading pulp-3.1.1-py3-none-any.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading quantecon-0.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.7/322.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (541 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m541.1/541.1 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading rasterstats-0.20.0-py3-none-any.whl (17 kB)\n",
            "Downloading fiona-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: spint\n",
            "  Building wheel for spint (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spint: filename=spint-1.0.7-py3-none-any.whl size=31354 sha256=57b249de719f3004ea40c98a8d8ad739cdca225089fcd64a56053e9bce1b3ef2\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/dc/2e/400caaa67e697355772a82b77b8c2ac7cd61633f595c477fd8\n",
            "Successfully built spint\n",
            "Installing collected packages: rtree, pulp, deprecation, quantecon, fiona, rasterstats, mapclassify, libpysal, access, tobler, spreg, segregation, pointpats, momepy, inequality, esda, spglm, spaghetti, giddy, spopt, splot, spint, mgwr, pysal\n",
            "Successfully installed access-1.1.9 deprecation-2.1.0 esda-2.7.0 fiona-1.10.1 giddy-2.3.6 inequality-1.1.1 libpysal-4.13.0 mapclassify-2.8.1 mgwr-2.2.1 momepy-0.10.0 pointpats-2.5.1 pulp-3.1.1 pysal-25.1 quantecon-0.8.0 rasterstats-0.20.0 rtree-1.4.0 segregation-2.5.2 spaghetti-1.7.6 spglm-1.1.0 spint-1.0.7 splot-1.1.7 spopt-0.6.1 spreg-1.8.2 tobler-0.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYyFgCnkn1sr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point\n",
        "import pysal as ps\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import matplotlib.colors as colors\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "import rasterio\n",
        "from rasterio.features import rasterize\n",
        "from esda.moran import Moran\n",
        "from libpysal.weights import Queen\n",
        "from libpysal.weights import KNN\n",
        "from splot.esda import plot_moran\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "import contextily as ctx"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Data Loading and Initial Exploration\n",
        "print(\"Loading datasets...\")\n",
        "\n",
        "# Load COVID-19 vaccination data by ZIP code\n",
        "covid_df = pd.read_csv('/content/covid19vaccinesbyzipcode_test.csv')\n",
        "print(f\"COVID-19 data shape: {covid_df.shape}\")\n",
        "print(\"COVID-19 data first few rows:\")\n",
        "print(covid_df.head())\n",
        "\n",
        "# Load Income limits by county\n",
        "income_df = pd.read_csv('/content/2023-income-limits.csv')\n",
        "print(f\"Income data shape: {income_df.shape}\")\n",
        "print(\"Income data first few rows:\")\n",
        "print(income_df.head())\n",
        "\n",
        "# Load California counties shapefile\n",
        "counties_gdf = gpd.read_file('/content/California_Counties.csv')\n",
        "print(f\"Counties shapefile shape: {counties_gdf.shape}\")\n",
        "print(\"Counties data first few rows:\")\n",
        "print(counties_gdf.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "_b3Doj5FFkx8",
        "outputId": "9a510a5f-ac1f-43d7-e080-143f28f23e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/covid19vaccinesbyzipcode_test.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d0402a5209de>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load COVID-19 vaccination data by ZIP code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcovid_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/covid19vaccinesbyzipcode_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"COVID-19 data shape: {covid_df.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"COVID-19 data first few rows:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/covid19vaccinesbyzipcode_test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Preprocessing\n",
        "\n",
        "# Examining data types and cleaning\n",
        "print(\"\\nExamining data types and basic statistics:\")\n",
        "print(covid_df.info())\n",
        "print(covid_df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in COVID data:\")\n",
        "print(covid_df.isnull().sum())\n",
        "print(\"\\nMissing values in income data:\")\n",
        "print(income_df.isnull().sum())\n",
        "\n",
        "# Filter to most recent data for each ZIP code (if time series)\n",
        "covid_df['as_of_date'] = pd.to_datetime(covid_df['as_of_date'])\n",
        "latest_covid_data = covid_df.sort_values('as_of_date').groupby('zip_code_tabulation_area').last().reset_index()\n",
        "print(f\"\\nFiltered to latest data per ZIP code: {latest_covid_data.shape}\")\n"
      ],
      "metadata": {
        "id": "IaNXCTJ8FoSt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "67cdc1e9-c1ef-4718-92ec-7e4b57cc98a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Examining data types and basic statistics:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'covid_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6da42936ff31>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Examining data types and cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nExamining data types and basic statistics:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovid_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'covid_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Spatial Data Processing\n",
        "print(\"\\nProcessing spatial data...\")\n",
        "\n",
        "# Try to load a proper California counties shapefile with geometry\n",
        "try:\n",
        "    # Option 1: Try loading from a standard source\n",
        "    counties_gdf = gpd.read_file('https://raw.githubusercontent.com/codeforgermany/click_that_hood/main/public/data/california-counties.geojson')\n",
        "    print(\"Loaded California counties shapefile from online source\")\n",
        "except:\n",
        "    print(\"Could not load counties shapefile from online source, trying alternative approach\")\n",
        "    # Option 2: If counties_df already has the data but needs conversion\n",
        "    counties_df = pd.read_csv('/content/California_Counties.csv')\n",
        "\n",
        "    # Check if there might be geometry data in the CSV\n",
        "    if 'Shape_Area' in counties_df.columns and 'Shape_Length' in counties_df.columns:\n",
        "        print(\"Found shape measurements but no actual geometry data\")\n",
        "\n",
        "        # If you have OBJECTID and NAME, you can still work with the data\n",
        "        if 'OBJECTID' in counties_df.columns and 'NAME' in counties_df.columns:\n",
        "            # Create a simple point geometry at California's center as placeholder\n",
        "            # This is just to have a geometric structure - not accurate boundaries\n",
        "            geometry = [Point(-119.4179, 36.7783) for _ in range(len(counties_df))]\n",
        "            counties_gdf = gpd.GeoDataFrame(counties_df, geometry=geometry, crs=\"EPSG:4326\")\n",
        "            print(\"Created GeoDataFrame with placeholder geometry\")\n",
        "        else:\n",
        "            print(\"Warning: Cannot create proper GeoDataFrame due to missing data\")\n",
        "            counties_gdf = gpd.GeoDataFrame(counties_df)\n",
        "    else:\n",
        "        print(\"No geometry information found in counties data\")\n",
        "        counties_gdf = gpd.GeoDataFrame(counties_df)\n",
        "\n",
        "# Print information about the counties GeoDataFrame\n",
        "print(f\"Counties GeoDataFrame info:\")\n",
        "print(f\"- Number of counties: {len(counties_gdf)}\")\n",
        "print(f\"- Columns: {counties_gdf.columns.tolist()}\")\n",
        "print(f\"- Has geometry column: {'geometry' in counties_gdf.columns}\")\n",
        "\n",
        "# Create a mapping from ZIP codes to counties\n",
        "# Use the county information already in the COVID data\n",
        "zip_to_county = latest_covid_data[['zip_code_tabulation_area', 'county']].drop_duplicates()\n",
        "print(\"ZIP to county mapping (sample):\")\n",
        "print(zip_to_county.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "meNemhvIGikD",
        "outputId": "cf0b2d94-896d-4ef5-d326-dc55347dd94e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing spatial data...\n",
            "Loaded California counties shapefile from online source\n",
            "Counties GeoDataFrame info:\n",
            "- Number of counties: 58\n",
            "- Columns: ['name', 'cartodb_id', 'created_at', 'updated_at', 'geometry']\n",
            "- Has geometry column: True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'latest_covid_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-6847fe8cf68d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Create a mapping from ZIP codes to counties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Use the county information already in the COVID data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mzip_to_county\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatest_covid_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'zip_code_tabulation_area'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'county'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ZIP to county mapping (sample):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_to_county\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'latest_covid_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Aggregate vaccination data to county level\n",
        "print(\"\\nAggregating vaccination data to county level...\")\n",
        "\n",
        "# Group by county and calculate statistics\n",
        "county_vax_stats = latest_covid_data.groupby('county').agg({\n",
        "    'percent_of_population_fully_vaccinated': 'mean',\n",
        "    'percent_of_population_partially_vaccinated': 'mean',\n",
        "    'percent_of_population_with_1_plus_dose': 'mean',\n",
        "    'tot_population': 'sum',\n",
        "    'persons_fully_vaccinated': 'sum',\n",
        "    'persons_partially_vaccinated': 'sum',\n",
        "    'vaccine_equity_metric_quartile': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "print(\"County-level vaccination statistics:\")\n",
        "print(county_vax_stats.head())"
      ],
      "metadata": {
        "id": "ZrkNtSfBHheA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "2270043d-480a-47cb-9b5c-3039a1107b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Aggregating vaccination data to county level...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'latest_covid_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7dd6459ff08a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Group by county and calculate statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m county_vax_stats = latest_covid_data.groupby('county').agg({\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m'percent_of_population_fully_vaccinated'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m'percent_of_population_partially_vaccinated'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'latest_covid_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Join vaccination data with county boundaries and income data\n",
        "print(\"\\nJoining datasets...\")\n",
        "\n",
        "# First, let's check what columns we actually have in our datasets\n",
        "print(\"County vaccination stats columns:\", county_vax_stats.columns.tolist())\n",
        "print(\"Counties GeoDataFrame columns:\", counties_gdf.columns.tolist())\n",
        "print(\"Income data columns:\", income_df.columns.tolist())\n",
        "\n",
        "# Clean county names for matching\n",
        "county_vax_stats['county'] = county_vax_stats['county'].str.title()\n",
        "\n",
        "# For counties_gdf, we need to find the appropriate county name column\n",
        "# It might be 'name', 'NAME', 'county', 'COUNTY', etc.\n",
        "county_name_cols = [col for col in counties_gdf.columns if 'name' in col.lower() or 'county' in col.lower()]\n",
        "print(\"Potential county name columns:\", county_name_cols)\n",
        "\n",
        "if 'NAME' in counties_gdf.columns:\n",
        "    counties_gdf['NAME'] = counties_gdf['NAME'].str.title()\n",
        "elif len(county_name_cols) > 0:\n",
        "    # Use the first appropriate column found\n",
        "    county_col = county_name_cols[0]\n",
        "    print(f\"Using '{county_col}' as county name column\")\n",
        "    # Rename it to 'NAME' for consistency\n",
        "    counties_gdf = counties_gdf.rename(columns={county_col: 'NAME'})\n",
        "    counties_gdf['NAME'] = counties_gdf['NAME'].str.title()\n",
        "else:\n",
        "    # If no name column found, but we have OBJECTID, create a name column\n",
        "    if 'OBJECTID' in counties_gdf.columns:\n",
        "        print(\"Creating county names from OBJECTID\")\n",
        "        # Map OBJECTID to county names if possible\n",
        "        objectid_to_name = {\n",
        "            1: 'Alameda County',\n",
        "            2: 'Alpine County',\n",
        "            3: 'Amador County',\n",
        "            # Add more mappings as needed\n",
        "        }\n",
        "        # Create NAME column or use a default naming scheme\n",
        "        counties_gdf['NAME'] = counties_gdf['OBJECTID'].map(objectid_to_name).fillna(\n",
        "            'County ' + counties_gdf['OBJECTID'].astype(str)\n",
        "        )\n",
        "    else:\n",
        "        print(\"Warning: No county name column found. Creating a dummy NAME column.\")\n",
        "        counties_gdf['NAME'] = [f\"County {i+1}\" for i in range(len(counties_gdf))]\n",
        "\n",
        "# Clean income data county names\n",
        "income_df['County'] = income_df['County'].str.title()\n",
        "\n",
        "# Add \"County\" to county_vax_stats county names if not present\n",
        "county_vax_stats['county_name'] = county_vax_stats['county'].apply(\n",
        "    lambda x: x if 'County' in x else f\"{x} County\"\n",
        ")\n",
        "\n",
        "# Print sample values to verify matching\n",
        "print(\"\\nSample county names for matching:\")\n",
        "print(\"Vaccination data:\", county_vax_stats['county_name'].unique()[:5])\n",
        "print(\"GeoDataFrame:\", counties_gdf['NAME'].unique()[:5])\n",
        "print(\"Income data:\", income_df['County'].unique()[:5])\n",
        "\n",
        "# Merge vaccination data with county boundaries\n",
        "counties_with_vax = counties_gdf.merge(\n",
        "    county_vax_stats,\n",
        "    left_on='NAME',\n",
        "    right_on='county_name',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# Extract just a few key income metrics for simplicity\n",
        "# Check if the columns exist first\n",
        "available_income_cols = [col for col in ['AMI', 'LI_1', 'VLI_1', 'ELI_1'] if col in income_df.columns]\n",
        "if not available_income_cols:\n",
        "    print(\"Warning: Expected income columns not found. Using first 3 numeric columns instead.\")\n",
        "    income_cols = income_df.select_dtypes(include=['number']).columns[:3].tolist()\n",
        "    income_metrics = income_df[['County'] + income_cols].copy()\n",
        "else:\n",
        "    income_metrics = income_df[['County'] + available_income_cols].copy()\n",
        "\n",
        "# Create consistent county name format\n",
        "income_metrics['county_name'] = income_metrics['County'].apply(\n",
        "    lambda x: x if 'County' in x else f\"{x} County\"\n",
        ")\n",
        "\n",
        "counties_with_all_data = counties_with_vax.merge(\n",
        "    income_metrics,\n",
        "    left_on='NAME',\n",
        "    right_on='county_name',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "print(\"Combined dataset shape:\", counties_with_all_data.shape)\n",
        "print(\"Combined dataset columns:\", counties_with_all_data.columns.tolist())\n",
        "print(counties_with_all_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "vcu1o9CRHmB5",
        "outputId": "2eef1b31-9b53-4d44-d9d3-39d0d816ec1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Joining datasets...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'county_vax_stats' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-a0f990bf9487>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# First, let's check what columns we actually have in our datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"County vaccination stats columns:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounty_vax_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Counties GeoDataFrame columns:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounties_gdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Income data columns:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincome_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'county_vax_stats' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Exploratory Data Analysis\n",
        "print(\"\\nPerforming exploratory analysis...\")\n",
        "\n",
        "# First, let's inspect what data we have in our datasets\n",
        "print(\"COVID data sample:\")\n",
        "print(county_vax_stats.head())\n",
        "print(\"\\nCounties GeoDataFrame sample:\")\n",
        "print(counties_gdf.head())\n",
        "print(\"\\nIncome data sample:\")\n",
        "print(income_df.head())\n",
        "\n",
        "# Since the join didn't work properly, let's try a different approach\n",
        "# First, check for common county identifiers across datasets\n",
        "print(\"\\nChecking column values for matching:\")\n",
        "if 'county' in county_vax_stats.columns:\n",
        "    print(\"Unique counties in vaccination data:\", county_vax_stats['county'].unique()[:5], \"...\")\n",
        "if 'NAME' in counties_gdf.columns:\n",
        "    print(\"Unique names in spatial data:\", counties_gdf['NAME'].unique()[:5], \"...\")\n",
        "if 'County' in income_df.columns:\n",
        "    print(\"Unique counties in income data:\", income_df['County'].unique()[:5], \"...\")\n",
        "\n",
        "# Manual approach to create a better joined dataset\n",
        "# This will help us see why the joins are failing\n",
        "data_combined = pd.DataFrame()\n",
        "\n",
        "# Check if we have county-level aggregated vaccination data\n",
        "if 'county' in county_vax_stats.columns:\n",
        "    # Start with the vaccination statistics\n",
        "    data_combined = county_vax_stats.copy()\n",
        "\n",
        "    # Print column names to help debug\n",
        "    print(\"\\nColumns in county vaccination stats:\")\n",
        "    print(county_vax_stats.columns.tolist())\n",
        "\n",
        "    # Ensure county names are consistent\n",
        "    data_combined['county_clean'] = data_combined['county'].str.strip().str.title()\n",
        "    # Remove \"County\" suffix if it exists for consistent matching\n",
        "    data_combined['county_match'] = data_combined['county_clean'].apply(\n",
        "        lambda x: x.replace(' County', '') if isinstance(x, str) else x\n",
        "    )\n",
        "\n",
        "    # Try to add income data\n",
        "    if 'County' in income_df.columns:\n",
        "        # Clean income county names\n",
        "        income_df['county_clean'] = income_df['County'].str.strip().str.title()\n",
        "        income_df['county_match'] = income_df['county_clean'].apply(\n",
        "            lambda x: x.replace(' County', '') if isinstance(x, str) else x\n",
        "        )\n",
        "\n",
        "        # Print for debugging\n",
        "        print(\"\\nUnique counties after cleaning:\")\n",
        "        print(\"In vaccination data:\", data_combined['county_match'].unique()[:5], \"...\")\n",
        "        print(\"In income data:\", income_df['county_match'].unique()[:5], \"...\")\n",
        "\n",
        "        # Merge income data on cleaned county names\n",
        "        income_cols = ['county_match', 'AMI', 'LI_1', 'VLI_1', 'ELI_1']\n",
        "        income_cols = [col for col in income_cols if col in income_df.columns]\n",
        "\n",
        "        if len(income_cols) > 1:  # Need at least county_match and one metric\n",
        "            data_combined = data_combined.merge(\n",
        "                income_df[income_cols],\n",
        "                on='county_match',\n",
        "                how='left'\n",
        "            )\n",
        "\n",
        "    # Check if we have data after merging\n",
        "    print(\"\\nData after merging income information:\")\n",
        "    print(data_combined.head())\n",
        "    print(f\"Shape: {data_combined.shape}\")\n",
        "\n",
        "    # Now add spatial data if available\n",
        "    if isinstance(counties_gdf, gpd.GeoDataFrame) and 'geometry' in counties_gdf.columns:\n",
        "        # Create a clean county name for matching\n",
        "        if 'NAME' in counties_gdf.columns:\n",
        "            counties_gdf['county_match'] = counties_gdf['NAME'].str.strip().str.title().apply(\n",
        "                lambda x: x.replace(' County', '') if isinstance(x, str) else x\n",
        "            )\n",
        "        elif 'name' in counties_gdf.columns:\n",
        "            counties_gdf['county_match'] = counties_gdf['name'].str.strip().str.title().apply(\n",
        "                lambda x: x.replace(' County', '') if isinstance(x, str) else x\n",
        "            )\n",
        "\n",
        "        # If we have county_match column, merge geometry\n",
        "        if 'county_match' in counties_gdf.columns:\n",
        "            print(\"\\nUnique counties in spatial data after cleaning:\",\n",
        "                  counties_gdf['county_match'].unique()[:5], \"...\")\n",
        "\n",
        "            # Create a GeoDataFrame with our combined data\n",
        "            # First get a list of counties that appear in both datasets\n",
        "            common_counties = set(data_combined['county_match']).intersection(set(counties_gdf['county_match']))\n",
        "            print(f\"\\nFound {len(common_counties)} common counties for mapping\")\n",
        "\n",
        "            if common_counties:\n",
        "                # Filter to matching counties\n",
        "                counties_subset = counties_gdf[counties_gdf['county_match'].isin(common_counties)]\n",
        "                data_subset = data_combined[data_combined['county_match'].isin(common_counties)]\n",
        "\n",
        "                # Merge based on the common counties\n",
        "                geo_combined = counties_subset.merge(\n",
        "                    data_subset,\n",
        "                    on='county_match',\n",
        "                    how='inner'\n",
        "                )\n",
        "\n",
        "                # Check if we have a valid GeoDataFrame with data\n",
        "                if isinstance(geo_combined, gpd.GeoDataFrame) and len(geo_combined) > 0:\n",
        "                    print(f\"Successfully created GeoDataFrame with {len(geo_combined)} counties\")\n",
        "                    counties_with_all_data = geo_combined\n",
        "                else:\n",
        "                    print(\"Failed to create valid GeoDataFrame\")\n",
        "                    counties_with_all_data = data_combined\n",
        "            else:\n",
        "                print(\"No common counties found, skipping spatial join\")\n",
        "                counties_with_all_data = data_combined\n",
        "        else:\n",
        "            print(\"No county matching column in spatial data, skipping spatial join\")\n",
        "            counties_with_all_data = data_combined\n",
        "    else:\n",
        "        print(\"No valid geometry data available, continuing with tabular analysis only\")\n",
        "        counties_with_all_data = data_combined\n",
        "else:\n",
        "    print(\"No county-level vaccination data available, cannot proceed with analysis\")\n",
        "    # Create an empty DataFrame to avoid errors\n",
        "    counties_with_all_data = pd.DataFrame()\n",
        "\n",
        "# Check if we have anything to analyze\n",
        "if counties_with_all_data.empty:\n",
        "    print(\"WARNING: No data available for analysis after merging\")\n",
        "else:\n",
        "    # Check columns in our final dataset\n",
        "    print(\"\\nColumns in final analysis dataset:\")\n",
        "    print(counties_with_all_data.columns.tolist())\n",
        "\n",
        "    # Basic statistics of vaccination rates (if column exists)\n",
        "    if 'percent_of_population_fully_vaccinated' in counties_with_all_data.columns:\n",
        "        vax_data = counties_with_all_data['percent_of_population_fully_vaccinated'].dropna()\n",
        "        if not vax_data.empty:\n",
        "            vax_stats = vax_data.describe()\n",
        "            print(\"\\nVaccination rate statistics:\")\n",
        "            print(vax_stats)\n",
        "        else:\n",
        "            print(\"\\nNo valid vaccination rate data available\")\n",
        "    else:\n",
        "        print(\"\\nVaccination rate column not found in final dataset\")\n",
        "\n",
        "    # Only create plots if we have data\n",
        "    if not counties_with_all_data.empty and 'percent_of_population_fully_vaccinated' in counties_with_all_data.columns:\n",
        "        if counties_with_all_data['percent_of_population_fully_vaccinated'].notna().any():\n",
        "            # Create a figure for multiple plots\n",
        "            plt.figure(figsize=(18, 12))\n",
        "\n",
        "            # Histogram of vaccination rates\n",
        "            plt.subplot(2, 2, 1)\n",
        "            sns.histplot(counties_with_all_data['percent_of_population_fully_vaccinated'].dropna(), kde=True)\n",
        "            plt.title('Distribution of Full Vaccination Rates by County')\n",
        "            plt.xlabel('Percent Fully Vaccinated')\n",
        "\n",
        "            # Boxplot of vaccination rates by vaccine equity metric quartile\n",
        "            plt.subplot(2, 2, 2)\n",
        "            if 'vaccine_equity_metric_quartile' in counties_with_all_data.columns and counties_with_all_data['vaccine_equity_metric_quartile'].notna().any():\n",
        "                # Convert to string category to avoid numeric ordering issues\n",
        "                counties_with_all_data['vem_category'] = counties_with_all_data['vaccine_equity_metric_quartile'].astype(str)\n",
        "\n",
        "                # Check we have at least one value in each category\n",
        "                vem_cats = counties_with_all_data.groupby('vem_category')['percent_of_population_fully_vaccinated'].count()\n",
        "                if (vem_cats > 0).all():\n",
        "                    sns.boxplot(x='vem_category',\n",
        "                                y='percent_of_population_fully_vaccinated',\n",
        "                                data=counties_with_all_data)\n",
        "                    plt.title('Vaccination Rates by Equity Metric Quartile')\n",
        "                    plt.xlabel('Vaccine Equity Metric Quartile')\n",
        "                    plt.ylabel('Percent Fully Vaccinated')\n",
        "                else:\n",
        "                    plt.text(0.5, 0.5, 'Insufficient data in categories',\n",
        "                             horizontalalignment='center', verticalalignment='center')\n",
        "                    plt.title('No Data for Boxplot')\n",
        "            else:\n",
        "                plt.text(0.5, 0.5, 'Equity metric data not available',\n",
        "                         horizontalalignment='center', verticalalignment='center')\n",
        "                plt.title('Missing Data')\n",
        "\n",
        "            # Scatter plot of vaccination rate vs median income (AMI)\n",
        "            plt.subplot(2, 2, 3)\n",
        "            if 'AMI' in counties_with_all_data.columns and counties_with_all_data['AMI'].notna().any():\n",
        "                # Filter to rows where both columns have values\n",
        "                scatter_data = counties_with_all_data[\n",
        "                    counties_with_all_data['percent_of_population_fully_vaccinated'].notna() &\n",
        "                    counties_with_all_data['AMI'].notna()\n",
        "                ]\n",
        "\n",
        "                if len(scatter_data) > 1:  # Need at least two points for scatter\n",
        "                    sns.scatterplot(x='AMI',\n",
        "                                    y='percent_of_population_fully_vaccinated',\n",
        "                                    data=scatter_data)\n",
        "                    plt.title('Vaccination Rate vs. Area Median Income')\n",
        "                    plt.xlabel('Area Median Income (AMI)')\n",
        "                    plt.ylabel('Percent Fully Vaccinated')\n",
        "                else:\n",
        "                    plt.text(0.5, 0.5, 'Insufficient paired data points',\n",
        "                             horizontalalignment='center', verticalalignment='center')\n",
        "                    plt.title('Insufficient Data')\n",
        "            else:\n",
        "                plt.text(0.5, 0.5, 'Income data not available',\n",
        "                         horizontalalignment='center', verticalalignment='center')\n",
        "                plt.title('Missing Data')\n",
        "\n",
        "            # Box plots comparing urban vs rural counties based on population\n",
        "            plt.subplot(2, 2, 4)\n",
        "            if 'tot_population' in counties_with_all_data.columns and counties_with_all_data['tot_population'].notna().any():\n",
        "                # Check if we have enough data for quantiles\n",
        "                pop_data = counties_with_all_data['tot_population'].dropna()\n",
        "                if len(pop_data) >= 3:\n",
        "                    # Create a copy to avoid SettingWithCopyWarning\n",
        "                    plot_data = counties_with_all_data.copy()\n",
        "\n",
        "                    # Create population categories\n",
        "                    try:\n",
        "                        plot_data['population_category'] = pd.qcut(\n",
        "                            plot_data['tot_population'].rank(method='first'),\n",
        "                            q=3,\n",
        "                            labels=['Low Population', 'Medium Population', 'High Population']\n",
        "                        )\n",
        "\n",
        "                        # Check we have data in each category\n",
        "                        pop_cats = plot_data.groupby('population_category')['percent_of_population_fully_vaccinated'].count()\n",
        "                        if (pop_cats > 0).all():\n",
        "                            sns.boxplot(x='population_category',\n",
        "                                        y='percent_of_population_fully_vaccinated',\n",
        "                                        data=plot_data)\n",
        "                            plt.title('Vaccination Rates by Population Size')\n",
        "                            plt.xlabel('Population Category')\n",
        "                            plt.ylabel('Percent Fully Vaccinated')\n",
        "                        else:\n",
        "                            plt.text(0.5, 0.5, 'Insufficient data in categories',\n",
        "                                     horizontalalignment='center', verticalalignment='center')\n",
        "                            plt.title('Category Data Insufficient')\n",
        "                    except Exception as e:\n",
        "                        plt.text(0.5, 0.5, f'Error creating population categories: {str(e)}',\n",
        "                                 horizontalalignment='center', verticalalignment='center')\n",
        "                        plt.title('Error in Categorization')\n",
        "                else:\n",
        "                    plt.text(0.5, 0.5, 'Insufficient population data for categories',\n",
        "                             horizontalalignment='center', verticalalignment='center')\n",
        "                    plt.title('Insufficient Data')\n",
        "            else:\n",
        "                plt.text(0.5, 0.5, 'Population data not available',\n",
        "                         horizontalalignment='center', verticalalignment='center')\n",
        "                plt.title('Missing Data')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.savefig('vaccination_eda_plots.png')\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"No valid vaccination data available for plotting\")\n",
        "    else:\n",
        "        print(\"No data available for plotting\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "rY2CkTxpIqtg",
        "outputId": "4c009116-5682-4807-a325-cd1b6d7f9060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing exploratory analysis...\n",
            "COVID data sample:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'county_vax_stats' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-07eb16e6bb3b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# First, let's inspect what data we have in our datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"COVID data sample:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounty_vax_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCounties GeoDataFrame sample:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounties_gdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'county_vax_stats' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Correlation Analysis\n",
        "print(\"\\nPerforming correlation analysis...\")\n",
        "\n",
        "# First, let's check what columns we have in our dataset\n",
        "print(\"Available columns:\", counties_with_all_data.columns.tolist())\n",
        "\n",
        "# Check which numeric columns are available\n",
        "available_numeric_cols = []\n",
        "for col in ['percent_of_population_fully_vaccinated',\n",
        "            'percent_of_population_partially_vaccinated',\n",
        "            'vaccine_equity_metric_quartile',\n",
        "            'AMI', 'LI_1', 'VLI_1', 'ELI_1']:\n",
        "    if col in counties_with_all_data.columns and counties_with_all_data[col].notna().any():\n",
        "        available_numeric_cols.append(col)\n",
        "\n",
        "if len(available_numeric_cols) >= 2:\n",
        "    print(f\"Using these columns for correlation analysis: {available_numeric_cols}\")\n",
        "\n",
        "    # Select numeric columns for correlation analysis\n",
        "    correlation_data = counties_with_all_data[available_numeric_cols].dropna()\n",
        "\n",
        "    if not correlation_data.empty and len(correlation_data) >= 3:  # Need at least 3 data points\n",
        "        # Calculate correlation matrix\n",
        "        correlation_matrix = correlation_data.corr()\n",
        "        print(\"Correlation matrix:\")\n",
        "        print(correlation_matrix)\n",
        "\n",
        "        # Visualize correlation matrix\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "        plt.title('Correlation Matrix of Vaccination and Socioeconomic Variables')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('correlation_matrix.png')\n",
        "        plt.show()\n",
        "\n",
        "        # Calculate correlations if we have vaccination and income data\n",
        "        if all(col in correlation_data.columns for col in ['percent_of_population_fully_vaccinated', 'AMI']):\n",
        "            try:\n",
        "                # Pearson correlation between vaccination rate and AMI\n",
        "                pearson_corr, p_value = stats.pearsonr(\n",
        "                    correlation_data['percent_of_population_fully_vaccinated'],\n",
        "                    correlation_data['AMI']\n",
        "                )\n",
        "                print(f\"Pearson correlation between vaccination rate and AMI: {pearson_corr:.3f} (p-value: {p_value:.4f})\")\n",
        "\n",
        "                # Spearman correlation (non-parametric, rank-based)\n",
        "                spearman_corr, p_value = stats.spearmanr(\n",
        "                    correlation_data['percent_of_population_fully_vaccinated'],\n",
        "                    correlation_data['AMI']\n",
        "                )\n",
        "                print(f\"Spearman correlation between vaccination rate and AMI: {spearman_corr:.3f} (p-value: {p_value:.4f})\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating correlations: {str(e)}\")\n",
        "        else:\n",
        "            print(\"Cannot calculate correlations: missing either vaccination rate or AMI data\")\n",
        "    else:\n",
        "        print(\"Warning: Correlation data is empty or insufficient after dropping missing values\")\n",
        "        print(f\"Found {len(correlation_data)} complete rows for correlation analysis\")\n",
        "else:\n",
        "    print(f\"Not enough numeric columns available for correlation analysis. Available: {available_numeric_cols}\")\n"
      ],
      "metadata": {
        "id": "hU9hKkkLJi0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "29800e9b-7711-443a-8c8e-e761b549df90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing correlation analysis...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'counties_with_all_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-34b01c6cbd5f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# First, let's check what columns we have in our dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available columns:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounties_with_all_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Check which numeric columns are available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'counties_with_all_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Regression Analysis\n",
        "print(\"\\nPerforming regression analysis...\")\n",
        "\n",
        "# Check if we have the necessary columns for regression\n",
        "required_cols = ['AMI', 'vaccine_equity_metric_quartile', 'percent_of_population_fully_vaccinated']\n",
        "missing_reg_cols = [col for col in required_cols if col not in counties_with_all_data.columns]\n",
        "\n",
        "if missing_reg_cols:\n",
        "    print(f\"Missing columns for regression: {missing_reg_cols}\")\n",
        "\n",
        "    # Check if we can do simple regression with just vaccination and AMI\n",
        "    if all(col in counties_with_all_data.columns for col in ['AMI', 'percent_of_population_fully_vaccinated']):\n",
        "        print(\"Attempting simple regression with just AMI and vaccination rate\")\n",
        "        regression_data = counties_with_all_data[['AMI', 'percent_of_population_fully_vaccinated']].dropna()\n",
        "\n",
        "        if len(regression_data) >= 5:  # Need at least a few data points for regression\n",
        "            # Simple regression model\n",
        "            X = regression_data[['AMI']]\n",
        "            y = regression_data['percent_of_population_fully_vaccinated']\n",
        "\n",
        "            # Add constant for intercept\n",
        "            X_with_const = sm.add_constant(X)\n",
        "\n",
        "            # Fit model\n",
        "            try:\n",
        "                model = sm.OLS(y, X_with_const).fit()\n",
        "                print(model.summary())\n",
        "\n",
        "                # Create regression scatter plot with line\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                sns.regplot(x='AMI', y='percent_of_population_fully_vaccinated', data=regression_data)\n",
        "                plt.title('Regression: Vaccination Rate vs Area Median Income')\n",
        "                plt.xlabel('Area Median Income (AMI)')\n",
        "                plt.ylabel('Percent Fully Vaccinated')\n",
        "                plt.grid(True, alpha=0.3)\n",
        "                plt.savefig('regression_plot.png')\n",
        "                plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"Error in simple regression: {str(e)}\")\n",
        "        else:\n",
        "            print(f\"Insufficient data for simple regression: only {len(regression_data)} complete rows\")\n",
        "    else:\n",
        "        print(\"Cannot perform any regression: missing both AMI and vaccination rate data\")\n",
        "else:\n",
        "    # We have all required columns, try multiple regression\n",
        "    regression_data = counties_with_all_data[required_cols].dropna()\n",
        "\n",
        "    if len(regression_data) >= 5:  # Need at least a few data points for regression\n",
        "        # Multiple regression model\n",
        "        try:\n",
        "            X = regression_data[['AMI', 'vaccine_equity_metric_quartile']]\n",
        "            y = regression_data['percent_of_population_fully_vaccinated']\n",
        "\n",
        "            # Add constant for intercept\n",
        "            X_with_const = sm.add_constant(X)\n",
        "\n",
        "            # Fit model\n",
        "            model = sm.OLS(y, X_with_const).fit()\n",
        "            print(model.summary())\n",
        "\n",
        "            # Create regression scatter plot with line\n",
        "            plt.figure(figsize=(10, 6))\n",
        "            sns.regplot(x='AMI', y='percent_of_population_fully_vaccinated', data=regression_data)\n",
        "            plt.title('Regression: Vaccination Rate vs Area Median Income')\n",
        "            plt.xlabel('Area Median Income (AMI)')\n",
        "            plt.ylabel('Percent Fully Vaccinated')\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.savefig('regression_plot.png')\n",
        "            plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"Error in multiple regression: {str(e)}\")\n",
        "    else:\n",
        "        print(f\"Insufficient data for multiple regression: only {len(regression_data)} complete rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "E26ocgUpKJ6F",
        "outputId": "426665c3-bb26-4b1c-c3b2-8be63cc23892"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performing regression analysis...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'counties_with_all_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-e00c04552eb8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Check if we have the necessary columns for regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrequired_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AMI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vaccine_equity_metric_quartile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'percent_of_population_fully_vaccinated'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmissing_reg_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequired_cols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounties_with_all_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmissing_reg_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e00c04552eb8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Check if we have the necessary columns for regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrequired_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AMI'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vaccine_equity_metric_quartile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'percent_of_population_fully_vaccinated'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmissing_reg_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequired_cols\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounties_with_all_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmissing_reg_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'counties_with_all_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Spatial Analysis\n",
        "print(\"\\nPerforming spatial analysis...\")\n",
        "\n",
        "# Check if we have spatial data\n",
        "if isinstance(counties_with_all_data, gpd.GeoDataFrame) and 'geometry' in counties_with_all_data.columns:\n",
        "    print(\"GeoDataFrame with geometry available\")\n",
        "\n",
        "    # Make sure we have a valid GeoDataFrame with geometry\n",
        "    spatial_data = counties_with_all_data.copy()\n",
        "\n",
        "    # Check for missing geometries\n",
        "    if spatial_data.geometry.isna().any():\n",
        "        print(f\"Warning: {spatial_data.geometry.isna().sum()} counties have missing geometry data\")\n",
        "        # Filter out rows with missing geometry\n",
        "        spatial_data = spatial_data.dropna(subset=['geometry'])\n",
        "        print(f\"Filtered to {len(spatial_data)} counties with valid geometry\")\n",
        "\n",
        "    # Check if we have vaccination data\n",
        "    if 'percent_of_population_fully_vaccinated' in spatial_data.columns:\n",
        "        # Check how many counties have vaccination data\n",
        "        vax_count = spatial_data['percent_of_population_fully_vaccinated'].notna().sum()\n",
        "        print(f\"Found {vax_count} counties with vaccination data\")\n",
        "x\n",
        "        if vax_count >= 4:  # Need at least 4 counties for spatial analysis\n",
        "            try:\n",
        "                # Filter data to remove NaN vaccination rates\n",
        "                spatial_data = spatial_data.dropna(subset=['percent_of_population_fully_vaccinated'])\n",
        "                print(f\"After removing NaNs, {len(spatial_data)} counties remain for spatial analysis\")\n",
        "\n",
        "                if len(spatial_data) >= 4:\n",
        "                    # Create spatial weights matrix for counties\n",
        "                    # Queen contiguity: counties that share any boundary point\n",
        "                    W = Queen.from_dataframe(spatial_data)\n",
        "\n",
        "                    # Calculate Moran's I for vaccination rates (testing for spatial autocorrelation)\n",
        "                    moran = Moran(spatial_data['percent_of_population_fully_vaccinated'], W)\n",
        "                    print(f\"Moran's I: {moran.I:.3f}\")\n",
        "                    print(f\"p-value: {moran.p_sim:.4f}\")\n",
        "\n",
        "                    # Plot Moran's I scatter plot\n",
        "                    plt.figure(figsize=(10, 8))\n",
        "                    plot_moran(moran, zstandard=True, figsize=(10, 8))\n",
        "                    plt.savefig('morans_i_plot.png')\n",
        "                    plt.show()\n",
        "\n",
        "                    # Create choropleth map of vaccination rates\n",
        "                    fig, ax = plt.subplots(figsize=(15, 10))\n",
        "                    spatial_data.plot(\n",
        "                        column='percent_of_population_fully_vaccinated',\n",
        "                        cmap='YlGnBu',\n",
        "                        linewidth=0.8,\n",
        "                        ax=ax,\n",
        "                        edgecolor='0.8',\n",
        "                        legend=True,\n",
        "                        legend_kwds={'label': \"Percent Fully Vaccinated\"}\n",
        "                    )\n",
        "                    ax.set_title('COVID-19 Vaccination Rates by County in California', fontsize=15)\n",
        "                    ax.set_axis_off()\n",
        "                    plt.savefig('vaccination_choropleth.png', dpi=300, bbox_inches='tight')\n",
        "                    plt.show()\n",
        "\n",
        "                    # 10. Bivariate Analysis - Create bivariate choropleth showing both vaccination and income\n",
        "                    if 'AMI' in spatial_data.columns and spatial_data['AMI'].notna().any():\n",
        "                        # Check if we have enough data for quantiles\n",
        "                        ami_count = spatial_data['AMI'].notna().sum()\n",
        "                        print(f\"Found {ami_count} counties with income data\")\n",
        "\n",
        "                        # Need at least 3 counties in each quantile (so 9 total)\n",
        "                        if len(spatial_data.dropna(subset=['percent_of_population_fully_vaccinated', 'AMI'])) >= 9:\n",
        "                            try:\n",
        "                                # Create a copy for bivariate analysis to avoid SettingWithCopyWarning\n",
        "                                bivar_data = spatial_data.dropna(subset=['percent_of_population_fully_vaccinated', 'AMI']).copy()\n",
        "\n",
        "                                # Create quantiles for both variables\n",
        "                                bivar_data['vax_quantile'] = pd.qcut(\n",
        "                                    bivar_data['percent_of_population_fully_vaccinated'].rank(method='first'),\n",
        "                                    3,\n",
        "                                    labels=['Low', 'Medium', 'High']\n",
        "                                )\n",
        "\n",
        "                                bivar_data['income_quantile'] = pd.qcut(\n",
        "                                    bivar_data['AMI'].rank(method='first'),\n",
        "                                    3,\n",
        "                                    labels=['Low', 'Medium', 'High']\n",
        "                                )\n",
        "\n",
        "                                # Create a bivariate category\n",
        "                                bivar_data['bivariate_category'] = bivar_data['vax_quantile'].astype(str) + '-' + bivar_data['income_quantile'].astype(str)\n",
        "\n",
        "                                # Map categories to color values (3x3 grid)\n",
        "                                bivariate_colors = {\n",
        "                                    'Low-Low': '#e8e8e8',      # Light gray\n",
        "                                    'Low-Medium': '#ace4e4',   # Light blue\n",
        "                                    'Low-High': '#5ac8c8',     # Medium blue\n",
        "                                    'Medium-Low': '#dfb0d6',   # Light purple\n",
        "                                    'Medium-Medium': '#a5add3', # Medium purple\n",
        "                                    'Medium-High': '#5698b9',   # Blue-purple\n",
        "                                    'High-Low': '#be64ac',     # Pink\n",
        "                                    'High-Medium': '#8c62aa',  # Purple\n",
        "                                    'High-High': '#3b4994'     # Dark blue\n",
        "                                }\n",
        "\n",
        "                                bivar_data['bivariate_color'] = bivar_data['bivariate_category'].map(bivariate_colors)\n",
        "\n",
        "                                # Print category counts to verify distribution\n",
        "                                print(\"Bivariate category counts:\")\n",
        "                                print(bivar_data['bivariate_category'].value_counts())\n",
        "\n",
        "                                # Plot bivariate choropleth\n",
        "                                fig, ax = plt.subplots(figsize=(15, 10))\n",
        "                                bivar_data.plot(\n",
        "                                    color=bivar_data['bivariate_color'],\n",
        "                                    linewidth=0.8,\n",
        "                                    ax=ax,\n",
        "                                    edgecolor='0.8'\n",
        "                                )\n",
        "\n",
        "                                # Create a custom legend\n",
        "                                from matplotlib.patches import Patch\n",
        "                                legend_elements = [\n",
        "                                    Patch(facecolor=color, label=cat)\n",
        "                                    for cat, color in bivariate_colors.items()\n",
        "                                    if cat in bivar_data['bivariate_category'].values\n",
        "                                ]\n",
        "                                ax.legend(handles=legend_elements,\n",
        "                                          title=\"Vaccination-Income Categories\\n(Vaccination-Income)\",\n",
        "                                          loc='lower right', frameon=True)\n",
        "\n",
        "                                ax.set_title('Bivariate Map of COVID-19 Vaccination Rates and Income by County', fontsize=15)\n",
        "                                ax.set_axis_off()\n",
        "                                plt.savefig('bivariate_choropleth.png', dpi=300, bbox_inches='tight')\n",
        "                                plt.show()\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error in bivariate analysis: {str(e)}\")\n",
        "                        else:\n",
        "                            print(\"Insufficient data for bivariate analysis after removing missing values\")\n",
        "                    else:\n",
        "                        print(\"Cannot perform bivariate analysis: missing AMI column or all values are NaN\")\n",
        "                else:\n",
        "                    print(\"After filtering, insufficient counties remain for spatial analysis\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error in spatial analysis: {str(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "        else:\n",
        "            print(\"Insufficient counties with vaccination data for spatial analysis\")\n",
        "    else:\n",
        "        print(\"Cannot perform spatial analysis: missing vaccination rate column\")\n",
        "else:\n",
        "    print(\"Cannot perform spatial analysis: missing geometry column or not a GeoDataFrame\")\n",
        "    print(f\"Type of counties_with_all_data: {type(counties_with_all_data)}\")\n",
        "    if 'geometry' not in counties_with_all_data.columns:\n",
        "        print(\"No geometry column in dataset\")\n",
        "\n",
        "# Save processed datasets if we have data\n",
        "try:\n",
        "    print(\"\\nSaving processed datasets...\")\n",
        "    # Check if we have a GeoDataFrame\n",
        "    if isinstance(counties_with_all_data, gpd.GeoDataFrame) and 'geometry' in counties_with_all_data.columns:\n",
        "        print(\"Saving as GeoJSON...\")\n",
        "        counties_with_all_data.to_file('california_counties_covid_income_analysis.geojson', driver='GeoJSON')\n",
        "\n",
        "    # Save as CSV (without geometry column if it exists)\n",
        "    if 'geometry' in counties_with_all_data.columns:\n",
        "        print(\"Saving CSV without geometry column...\")\n",
        "        counties_with_all_data.drop('geometry', axis=1).to_csv('california_counties_covid_income_analysis.csv', index=False)\n",
        "    else:\n",
        "        print(\"Saving as CSV...\")\n",
        "        counties_with_all_data.to_csv('california_counties_covid_income_analysis.csv', index=False)\n",
        "\n",
        "    print(\"Output files have been saved.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving data: {str(e)}\")\n",
        "\n",
        "# 13. Generate summary statistics for the paper\n",
        "print(\"\\nGenerating summary statistics for the research paper...\")\n",
        "\n",
        "# Initialize empty dictionary for stats\n",
        "summary_stats = {'total_counties': len(counties_with_all_data)}\n",
        "\n",
        "# Add vaccination statistics if available\n",
        "if 'percent_of_population_fully_vaccinated' in counties_with_all_data.columns:\n",
        "    vax_data = counties_with_all_data['percent_of_population_fully_vaccinated'].dropna()\n",
        "    if not vax_data.empty:\n",
        "        summary_stats.update({\n",
        "            'mean_vax_rate': vax_data.mean(),\n",
        "            'median_vax_rate': vax_data.median(),\n",
        "            'min_vax_rate': vax_data.min(),\n",
        "            'max_vax_rate': vax_data.max(),\n",
        "            'std_vax_rate': vax_data.std(),\n",
        "            'counties_with_vax_data': len(vax_data)\n",
        "        })\n",
        "    else:\n",
        "        summary_stats['counties_with_vax_data'] = 0\n",
        "\n",
        "# Add correlation stats if they were calculated\n",
        "if 'pearson_corr' in locals() and 'p_value' in locals():\n",
        "    summary_stats.update({\n",
        "        'pearson_corr_vax_income': pearson_corr,\n",
        "        'pearson_pvalue': p_value\n",
        "    })\n",
        "\n",
        "# Add Moran's I stats if they were calculated\n",
        "if 'moran' in locals():\n",
        "    summary_stats.update({\n",
        "        'morans_i': moran.I,\n",
        "        'morans_i_pvalue': moran.p_sim\n",
        "    })\n",
        "\n",
        "print(\"Summary Statistics for Research Paper:\")\n",
        "for key, value in summary_stats.items():\n",
        "    if isinstance(value, float):\n",
        "        print(f\"{key}: {value:.4f}\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "# 14. Additional visualizations if we have enough data\n",
        "print(\"\\nCreating additional visualizations for the paper...\")\n",
        "\n",
        "# Check which variables are available\n",
        "available_vars = []\n",
        "for col in ['percent_of_population_fully_vaccinated', 'AMI',\n",
        "            'vaccine_equity_metric_quartile', 'tot_population']:\n",
        "    if col in counties_with_all_data.columns and counties_with_all_data[col].notna().any():\n",
        "        available_vars.append(col)\n",
        "\n",
        "if len(available_vars) >= 2:\n",
        "    print(f\"Can create scatter matrix with these variables: {available_vars}\")\n",
        "\n",
        "    # Create a copy of the data with just these variables\n",
        "    scatter_data = counties_with_all_data[available_vars].copy().dropna()\n",
        "\n",
        "    if len(scatter_data) >= 3:  # Need at least a few points for a meaningful scatter matrix\n",
        "        # Create more user-friendly column names\n",
        "        col_mapping = {\n",
        "            'percent_of_population_fully_vaccinated': 'Vaccination Rate',\n",
        "            'AMI': 'Median Income',\n",
        "            'vaccine_equity_metric_quartile': 'Equity Metric',\n",
        "            'tot_population': 'Population'\n",
        "        }\n",
        "\n",
        "        rename_cols = {col: col_mapping.get(col, col) for col in scatter_data.columns if col in col_mapping}\n",
        "        scatter_data = scatter_data.rename(columns=rename_cols)\n",
        "\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        scatter_matrix = pd.plotting.scatter_matrix(\n",
        "            scatter_data,\n",
        "            alpha=0.8,\n",
        "            figsize=(12, 10),\n",
        "            diagonal='kde'\n",
        "        )\n",
        "        plt.suptitle('Scatter Plot Matrix of Key Variables', fontsize=16, y=0.95)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('scatter_matrix.png', dpi=300)\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"Insufficient data for scatter plot matrix: only {len(scatter_data)} complete rows\")\n",
        "else:\n",
        "    print(f\"Not enough variables available for scatter matrix. Available: {available_vars}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "F9YOl5vqKcun",
        "outputId": "503baac1-4501-44fa-872b-c366f67ef48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 147)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m147\u001b[0m\n\u001b[0;31m    else:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = Queen.from_dataframe(counties_with_all_data)\n",
        "\n",
        "y = counties_with_all_data['percent_of_population_fully_vaccinated']\n",
        "lisa = Moran_Local(y, W)\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
        "lisa_cluster(lisa, counties_with_all_data, p=0.05, ax=ax)\n",
        "plt.title(\"Local Moran's I Cluster Map (Vaccination Rates)\")\n",
        "plt.show()\n",
        "sample_county = 'Los Angeles County'\n",
        "county_data = time_series_data[time_series_data['county'] == sample_county]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(county_data['as_of_date'], county_data['percent_of_population_fully_vaccinated'], marker='o', linestyle='-')\n",
        "plt.title(f'Vaccination Progress in {sample_county}')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Percent Fully Vaccinated')\n",
        "plt.grid(True, alpha=0.5)\n",
        "plt.show()\n",
        "\n",
        "slopes = []\n",
        "counties = time_series_data['county'].unique()\n",
        "\n",
        "for county in counties:\n",
        "    county_data = time_series_data[time_series_data['county'] == county]\n",
        "    if len(county_data) >= 2:\n",
        "        X = np.arange(len(county_data)).reshape(-1, 1)\n",
        "        y = county_data['percent_of_population_fully_vaccinated'].values\n",
        "        model = LinearRegression().fit(X, y)\n",
        "        slopes.append((county, model.coef_[0]))\n",
        "\n",
        "sorted_slopes = sorted(slopes, key=lambda x: x[1], reverse=True)\n",
        "print(\"Top counties with fastest vaccination uptake:\", sorted_slopes[:5])\n",
        "print(\"Top counties with slowest vaccination uptake:\", sorted_slopes[-5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "RkOPLgz44dHi",
        "outputId": "597b5937-fa6c-44e2-ae3d-fdfb955002ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'counties_with_all_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-7ac5b399f3bb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounties_with_all_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounties_with_all_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percent_of_population_fully_vaccinated'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlisa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoran_Local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'counties_with_all_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W = Queen.from_dataframe(counties_with_all_data)\n",
        "\n",
        "y = counties_with_all_data['percent_of_population_fully_vaccinated']\n",
        "lisa = Moran_Local(y, W)\n",
        "\n",
        "fig, ax = plt.subplots(1, figsize=(12, 8))\n",
        "lisa_cluster(lisa, counties_with_all_data, p=0.05, ax=ax)\n",
        "plt.title(\"Local Moran's I Cluster Map (Vaccination Rates)\")\n",
        "plt.show()\n",
        "\n",
        "counties_with_all_data['vax_quantile'] = pd.qcut(\n",
        "    counties_with_all_data['percent_of_population_fully_vaccinated'].rank(method='first'), 3, labels=['Low', 'Medium', 'High']\n",
        ")\n",
        "counties_with_all_data['income_quantile'] = pd.qcut(\n",
        "    counties_with_all_data['AMI'].rank(method='first'), 3, labels=['Low', 'Medium', 'High']\n",
        ")\n",
        "\n",
        "counties_with_all_data['bivariate_category'] = counties_with_all_data['vax_quantile'].astype(str) + '-' + counties_with_all_data['income_quantile'].astype(str)\n",
        "counties_with_all_data['bivariate_color'] = counties_with_all_data['bivariate_category'].map(bivariate_colors)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 10))\n",
        "counties_with_all_data.plot(\n",
        "    color=counties_with_all_data['bivariate_color'], linewidth=0.8, ax=ax, edgecolor='0.8'\n",
        ")\n",
        "\n",
        "legend_elements = [\n",
        "    Patch(facecolor=color, label=cat)\n",
        "    for cat, color in bivariate_colors.items() if cat in counties_with_all_data['bivariate_category'].values\n",
        "]\n",
        "ax.legend(handles=legend_elements, title=\"Vaccination-Income Categories\\n(Vaccination-Income)\", loc='lower right')\n",
        "ax.set_title('Bivariate Map of COVID-19 Vaccination Rates and Income by County', fontsize=15)\n",
        "ax.set_axis_off()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "JBnI3ma6_Ht0",
        "outputId": "07b5d40b-45a9-4d62-b2da-5caef438ef0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'counties_with_all_data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-1444510a0774>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQueen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounties_with_all_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcounties_with_all_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'percent_of_population_fully_vaccinated'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlisa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoran_Local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'counties_with_all_data' is not defined"
          ]
        }
      ]
    }
  ]
}